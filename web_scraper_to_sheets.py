import os
from datetime import datetime, timedelta
import time
import traceback

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException

from google.oauth2 import service_account
from googleapiclient.discovery import build

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
SERVICE_ACCOUNT_FILE = 'service_account_credentials.json'
SPREADSHEET_ID = '1L_sPHkWw6nzVWCFUXnTVUuCNyJjogmyM90iFCIvluD8'
SHEET_NAME = 'FDA_WL'
SCOPES = ['https://www.googleapis.com/auth/spreadsheets']
FILTER_KEYWORD = 'Finished Pharmaceuticals'
INITIAL_LOOK_BACK_YEARS = 3
MAX_PAGES = 50
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #

# Actions í™˜ê²½: GOOGLE_CREDENTIALS ì‹œí¬ë¦¿ìœ¼ë¡œ credentials.json íŒŒì¼ ìƒì„±
if os.getenv("GOOGLE_CREDENTIALS"):
    with open(SERVICE_ACCOUNT_FILE, "w") as f:
        f.write(os.getenv("GOOGLE_CREDENTIALS"))

# --- Google Sheets API ì¸ì¦ ---
try:
    credentials = service_account.Credentials.from_service_account_file(
        SERVICE_ACCOUNT_FILE, scopes=SCOPES)
    sheet_service = build('sheets', 'v4', credentials=credentials)
    sheet = sheet_service.spreadsheets()
    print("âœ… êµ¬ê¸€ ì‹œíŠ¸ ì¸ì¦ ì„±ê³µ")
except Exception as e:
    print(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì¸ì¦ ì‹¤íŒ¨: {e}")
    exit()


# --- ê¸°ì¤€ ë‚ ì§œ ê³„ì‚° í•¨ìˆ˜ ---
def parse_date(date_str):
    for fmt in ('%B %d, %Y', '%m/%d/%Y'):
        try:
            return datetime.strptime(date_str.strip(), fmt)
        except (ValueError, TypeError):
            continue
    return None


# --- Selenium ì›¹ ë“œë¼ì´ë²„ ì„¤ì • ---
options = webdriver.ChromeOptions()
options.add_argument('--headless')
options.add_argument('--disable-blink-features=AutomationControlled')
options.add_argument('--disable-gpu')
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')
options.add_argument("--window-size=1920,1080")
options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
options.add_experimental_option("excludeSwitches", ["enable-automation"])
options.add_experimental_option('useAutomationExtension', False)

print("ğŸ–¥ï¸ ì›¹ ë“œë¼ì´ë²„ ì‹¤í–‰ ì‹œì‘")
driver = webdriver.Chrome(service=Service(), options=options)
driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
wait = WebDriverWait(driver, 20)


def save_debug_info(name_prefix):
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    with open(f'{name_prefix}_page_{timestamp}.html', 'w', encoding='utf-8') as f:
        f.write(driver.page_source)
    driver.save_screenshot(f'{name_prefix}_screenshot_{timestamp}.png')
    print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥ë¨: {name_prefix}_screenshot_{timestamp}.png")
    print(f"ğŸ“„ HTML ì €ì¥ë¨: {name_prefix}_page_{timestamp}.html")

try:
    #########################################################################
    # 1ë¶€: ìƒˆë¡œìš´ Warning Letter ëª©ë¡ ìˆ˜ì§‘ ë° ì‹œíŠ¸ ì¶”ê°€
    #########################################################################
    print("\n" + "=" * 20 + " 1ë¶€: ì‹ ê·œ ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘ " + "=" * 20)

    print("ğŸ“Š êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ë§ˆì§€ë§‰ ë‚ ì§œë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    result = sheet.values().get(spreadsheetId=SPREADSHEET_ID, range=f'{SHEET_NAME}!A2:A2').execute()
    values = result.get('values', [])
    if values and values[0]:
        most_recent_saved_date = parse_date(values[0][0])
        start_date = most_recent_saved_date - timedelta(days=2)
        print(f"ğŸ”„ ë§ˆì§€ë§‰ ì €ì¥ ë‚ ì§œ({most_recent_saved_date.strftime('%Y-%m-%d')}) ì´í›„ì˜ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.")
    else:
        start_date = datetime.now() - timedelta(days=365 * INITIAL_LOOK_BACK_YEARS)
        print(f"ğŸš€ ì²« ì‹¤í–‰ì…ë‹ˆë‹¤. ì•½ {INITIAL_LOOK_BACK_YEARS}ë…„ ì „ì˜ ë°ì´í„°ë¶€í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    date_str_set = set(
        (start_date + timedelta(days=i)).strftime('%m/%d/%Y') for i in range((datetime.now() - start_date).days + 1))
    print(f"ğŸ“… ë°ì´í„° ê²€ìƒ‰ ë²”ìœ„: {start_date.strftime('%Y-%m-%d')} ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€")

    base_url = 'https://www.fda.gov/inspections-compliance-enforcement-and-criminal-investigations/compliance-actions-and-activities/warning-letters'
    try:
        driver.get(base_url)
    except Exception as e:
        print("âŒ í˜ì´ì§€ ì´ˆê¸° ë¡œë”© ì‹¤íŒ¨:", e)
        save_debug_info("initial_load")
        raise

    try:
        search_input = wait.until(EC.visibility_of_element_located((By.ID, 'edit-search-api-fulltext')))
        search_input.send_keys(FILTER_KEYWORD)
        time.sleep(4)
        info_element = wait.until(EC.visibility_of_element_located((By.ID, 'datatable_info')))
        print(f"ğŸ“Š ê²€ìƒ‰ ì •ë³´: {info_element.text}")
    except Exception as e:
        print("âŒ í˜ì´ì§€ ìš”ì†Œ íƒìƒ‰ ì‹¤íŒ¨:", e)
        save_debug_info("element_error")
        raise

    collected_rows = []
    for page in range(1, MAX_PAGES + 1):
        print(f"ğŸ“„ í˜ì´ì§€ {page} ì²˜ë¦¬ ì¤‘...")
        try:
            table_body = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, "#datatable > tbody")))
            rows = table_body.find_elements(By.TAG_NAME, "tr")
        except Exception as e:
            print(f"âŒ í…Œì´ë¸” ë¡œë”© ì‹¤íŒ¨: {e}")
            save_debug_info("table_error")
            break

        if len(rows) == 1 and "No matching records found" in rows[0].text:
            break

        for row in rows:
            cols = row.find_elements(By.TAG_NAME, 'td')
            if len(cols) < 5: continue
            posted_date = cols[0].text.strip()
            if posted_date in date_str_set:
                issue_date = cols[1].text.strip()
                company_name = cols[2].text.strip()
                subject = cols[4].text.strip()
                try:
                    link = cols[2].find_element(By.TAG_NAME, 'a').get_attribute('href')
                except NoSuchElementException:
                    link = ''
                print(f"  -> ëª©ë¡ ìˆ˜ì§‘: {posted_date}, {company_name}")
                collected_rows.append([posted_date, issue_date, company_name, subject, link])

        # ë‹¤ìŒ í˜ì´ì§€ ì´ë™
        try:
            pagination_info_element = driver.find_element(By.ID, "datatable_paginate")
            if 'class="paginate_button page-item next disabled"' in pagination_info_element.get_attribute('innerHTML'):
                print("ë§ˆì§€ë§‰ í˜ì´ì§€ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤."); break
            driver.execute_script("jQuery('#datatable').DataTable().page('next').draw('page');")
            time.sleep(3)
        except Exception as e:
            print(f"í˜ì´ì§€ ì´ë™ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"); break

    # ì¤‘ë³µ ì œê±° ë° ì‹œíŠ¸ ì €ì¥
    if collected_rows:
        existing_links_result = sheet.values().get(spreadsheetId=SPREADSHEET_ID, range=f'{SHEET_NAME}!E2:E').execute()
        existing_links = set(row[0] for row in existing_links_result.get('values', []) if row)
        new_rows = [row for row in collected_rows if row[4] not in existing_links]
        if new_rows:
            body = {'values': new_rows}
            sheet.values().append(spreadsheetId=SPREADSHEET_ID, range=f'{SHEET_NAME}!A2',
                                  valueInputOption='RAW', insertDataOption='INSERT_ROWS',
                                  body=body).execute()
            print(f"âœ… 1ë¶€: êµ¬ê¸€ ì‹œíŠ¸ì— {len(new_rows)}ê°œ í–‰ ì¶”ê°€ ì™„ë£Œ")
        else:
            print("ğŸ“­ 1ë¶€: ì €ì¥í•  ìƒˆë¡œìš´ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print("ğŸ“­ 1ë¶€: ìƒˆë¡œ ì¶”ê°€í•  ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")

    print("=" * 20 + " 1ë¶€: ì‹ ê·œ ëª©ë¡ ìˆ˜ì§‘ ì™„ë£Œ " + "=" * 20)

    #########################################################################
    # 2ë¶€: ë¹„ì–´ìˆëŠ” 'Body Content' ì—´ ì±„ìš°ê¸°
    #########################################################################
    print("\n" + "=" * 20 + " 2ë¶€: ë³¸ë¬¸ ë‚´ìš© ì±„ìš°ê¸° ì‹œì‘ " + "=" * 20)

    result = sheet.values().get(spreadsheetId=SPREADSHEET_ID, range=f'{SHEET_NAME}!A2:F').execute()
    all_rows = result.get('values', [])

    tasks = []
    for index, row in enumerate(all_rows):
        row_number = index + 2
        if len(row) >= 5 and row[4] and (len(row) < 6 or not row[5]):
            tasks.append({'link': row[4], 'cell': f'F{row_number}'})

    for i, task in enumerate(tasks):
        link = task['link']
        cell = task['cell']
        print(f"({i+1}/{len(tasks)}) ì‘ì—… ì¤‘ -> {link}")
        try:
            driver.get(link)
            body_element = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.article-body")))
            body_content = body_element.text.strip()
            body = {'values': [[body_content]]}
            sheet.values().update(spreadsheetId=SPREADSHEET_ID, range=f'{SHEET_NAME}!{cell}',
                                  valueInputOption='RAW', body=body).execute()
            print(f"    -> ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {cell}")
            time.sleep(1)
        except TimeoutException:
            print("    -> ë³¸ë¬¸ ë‚´ìš© íƒ€ì„ì•„ì›ƒ. ê±´ë„ˆëœë‹ˆë‹¤.")
        except Exception as e:
            print(f"    -> ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")

    print("âœ… 2ë¶€: ë³¸ë¬¸ ì±„ìš°ê¸° ì‘ì—… ì™„ë£Œ")

except Exception as e:
    print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
    traceback.print_exc()
    save_debug_info("general_error")

finally:
    driver.quit()
    print("ğŸ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
